# Always On AI

## üßê O que √©?

**Always On AI** √© um sistema de IA que participa de todas as reuni√µes da empresa, age como um **s√≥cio digital inteligente**, e transforma cada conversa em **decis√µes mais r√°pidas, embasadas e produtivas**.

N√£o √© s√≥ mais um _notetaker_. Ele entende o que est√° sendo falado, **busca dados internos e externos em tempo real**, e pode agir por conta pr√≥pria para **acelerar decis√µes, corrigir erros e gerar insights de impacto**.

---

## üîß Dois Modos de Opera√ß√£o

### üßë‚Äçüíº 1. Assistant Mode (Precisa ser acionada)

~ Durante discuss√£o para decis√£o estrat√©gica.

> ‚ÄúHey S√≥cio, o que acha sobre isso?‚Äù

Nesse modo, a IA √© **ativada por uma frase** e pode responder a qualquer pergunta com base no **contexto da reuni√£o e nos dados da empresa**.

#### Como funciona:

- Escuta ativa com buffer de 5 minutos
- Frase de ativa√ß√£o ‚Üí `"Fala S√≥cio"`
- Abre sess√£o via WebSocket (Speech to Speech)
- Acessa dados internos (CRM, Docs, etc.)
- Responde por voz e fecha sess√£o automaticamente

#### Exemplo real:

Suponha que estamos discutindo qual oferta ser√° feita para a audi√™ncia do Adapta Summit. Ou seja, qual o melhor produto e melhor pitch a ser feito.

> ‚ÄúFala s√≥cio, o que acha sobre isso?‚Äù

A IA j√° tem o contexto do que est√° sendo discutido, acessa **HubSpot (CRM)** para entender o p√∫blico do evento, mapeia as principais dores daquela persona, confere documenta√ß√µes sobre seus produtos no Notion, e d√° a **resposta final para decis√£o em segundos com insights valiosos**.

---

### ‚ö° 2. Proactive Triggers (Gatilhos proativos)

> A IA entra na conversa **mesmo sem ser chamada**.

Ela detecta **palavras-chave importantes**, valida se √© o momento certo de agir, e **age proativamente** trazendo **informa√ß√µes, alertas ou corre√ß√µes**.

#### Como funciona:

- Escaneia tudo que est√° sendo dito (<10ms)
- Detecta keywords relevantes
- Valida com LLM se √© √∫til agir
- Executa a√ß√£o (dados, API, c√°lculo)
- Fala com naturalidade no momento certo e em real-time.

#### Exemplo:

Algu√©m do comercial diz:

> ‚Äú... creio que empresas de tecnologia representam muito pouco do nosso faturamento.‚Äù

‚Üí A IA confere o CRM, analisa esse dado e responde:

> ‚ÄúNa verdade, empresas de tecnologia representam 33%, o que √© uma parcela expressiva.‚Äù

---

## üöÄ Diferenciais do Produto

- ‚úÖ **Contexto sempre presente**: Recentemente, muito tem se falado sobre **Context Engineering**.
- üîå **Integra√ß√£o plug-and-play**: a AlwaysOn s√≥ precisa ser configurada 1x, minimizando a fric√ß√£o de uso por usu√°rios.
- üîÅ **Atua√ß√£o reativa + proativa**
- üí∏ **Redu√ß√£o extrema de custo por sess√£o** (de ~US$300/h para ~US$3/h): A arquitetura combina Text-to-Speech (TTS) com Speech-to-Speech, otimizando custos ao manter a IA principalmente em modo de escuta e falando apenas quando necess√°rio.
- üìà **Base escal√°vel** com foco em multi-times, multi-canais e multi-setores

---

## üî≠ Roadmap de Evolu√ß√£o

### ‚úÖ J√° entregue:

- IA funcional
- Modo reativo e proativo
- Integra√ß√µes com HubSpot (CRM) + Notion (Docs internas)
- Arquitetura de custo otimizado

### üîú Pr√≥ximas etapas:

- Autentica√ß√£o e suporte multi-equipe
- Novas integra√ß√µes: Google Meet, Slack, Teams...
- Analytics de produtividade
- Dashboard executivo
- Suporte multimodal (v√≠deo, docs, tela...)
- Workflows customizados por setor
- Marketplace de agentes especializados

---

## üìã Pr√©-requisitos

Para executar o Always On AI, voc√™ precisar√°:

- **Python 3.8+** instalado
- **Node.js 16+** e **npm** (para o dashboard)
- **PyAudio** (requer depend√™ncias do sistema)
- **API Key da OpenAI** configurada

### Instala√ß√£o de Depend√™ncias do Sistema

#### macOS
```bash
brew install portaudio
```

#### Ubuntu/Debian
```bash
sudo apt-get update
sudo apt-get install portaudio19-dev python3-pyaudio
```

#### Windows
PyAudio geralmente funciona sem instala√ß√µes adicionais no Windows.

---

## üöÄ Como Executar

### In√≠cio R√°pido (Com Dashboard)

A maneira mais f√°cil de executar o sistema completo:

```bash
# Clone o reposit√≥rio
git clone https://github.com/your-repo/always-on-ai.git
cd always-on-ai

# Configure as vari√°veis de ambiente
cp .env.example .env
# Edite .env e adicione sua OPENAI_API_KEY

# Instale as depend√™ncias Python
pip install -r requirements.txt

# Execute com dashboard
./scripts/run_with_dashboard.sh
```

O sistema estar√° dispon√≠vel em:
- **Dashboard**: http://localhost:3000
- **WebSocket Context**: ws://localhost:8765
- **API REST**: http://localhost:8766

### Executando Componentes Separadamente

#### 1. Apenas o Assistente de Voz
```bash
python main.py
```

#### 2. Apenas o Dashboard
```bash
cd dashboard
npm install
npm run dev
```

#### 3. Com Script Python (Alternativo)
```bash
python scripts/run_with_dashboard.py
```

### Configura√ß√µes de Execu√ß√£o

O sistema pode ser configurado atrav√©s de vari√°veis de ambiente ou editando `config.py`:

- **Modo de Transcri√ß√£o**: Configur√°vel entre tempo real ou batch
- **Triggers Ativos**: Habilite/desabilite triggers espec√≠ficos
- **Integra√ß√µes**: Configure APIs externas (HubSpot, Notion, etc.)

---

## üèóÔ∏è Arquitetura

### Vis√£o Geral da Arquitetura

![Architecture Overview](architecture/architecture_overview.png)

O Always On AI possui uma arquitetura modular e escal√°vel que processa √°udio em tempo real:

1. **Pipeline de √Åudio (PyAudio)**:
   - Captura de voz com detec√ß√£o de dispositivo
   - Preven√ß√£o de feedback inteligente
   - Smart buffering para contexto

2. **Transcri√ß√£o em Tempo Real**:
   - Low Latency Realtime Transcription
   - Context Pool para manter √∫ltimos 5 minutos
   - Trigger Manager para detec√ß√£o de palavras-chave

3. **Valida√ß√£o e Execu√ß√£o**:
   - LLM Context Validation para relev√¢ncia
   - Action Factory para executar a√ß√µes
   - Tools/MCP Server para integra√ß√µes externas

4. **Resposta por Voz**:
   - TTS Pipeline para s√≠ntese de voz
   - VAD (Voice Activity Detection) para timing natural
   - Session management para controle de conversas

### Modo Assistant

![Assistant Mode](architecture/assistant_mode.png)

O Modo Assistant √© ativado por frases de ativa√ß√£o ("Fala S√≥cio"):

1. **Ativa√ß√£o e Gerenciamento de Sess√£o**:
   - Context Pool mant√©m buffer de 5 minutos
   - Detec√ß√£o de trigger abre websocket
   - Session Manager controla lifecycle

2. **Integra√ß√£o com API Realtime**:
   - Conex√£o WebSocket com OpenAI
   - Tools para acesso a dados externos
   - Interruption handling com VAD

3. **Gerenciamento de Sess√£o**:
   - Detec√ß√£o autom√°tica de fim de conversa
   - Context Manager preserva hist√≥rico
   - Microphone muting durante respostas

### Proactive Triggers

![Proactive Triggers](architecture/proactive_triggers.png)

Sistema de gatilhos proativos em 4 est√°gios:

1. **Stage 1: Detec√ß√£o de Keywords (<10ms)**:
   - String Match, Case Ignore, Fuzzy Match
   - Keyword Scanner ultra-r√°pido
   - Trigger Registry com gatilhos dispon√≠veis

2. **Stage 2: Valida√ß√£o LLM (500-2000ms)**:
   - Thread Pool Manager paralelo
   - Validation Task com templates Jinja2
   - Confidence Scores e Aggregator

3. **Stage 3: Execu√ß√£o de A√ß√µes**:
   - Action Factory din√¢mica
   - APIs externas (HubSpot, Notion, etc.)
   - Data enrichment em tempo real

4. **Stage 4: Gera√ß√£o de Resposta e TTS**:
   - Response Queue ass√≠ncrona
   - TTS Pipeline otimizado
   - Audio Output com timing natural

---

## üìÅ Estrutura do Projeto

```
always-on-ai/
‚îú‚îÄ‚îÄ audio/                    # Pipeline de captura e processamento de √°udio
‚îÇ   ‚îú‚îÄ‚îÄ audio_stream.py      # Gerenciador de stream de √°udio
‚îÇ   ‚îú‚îÄ‚îÄ conversation_handler.py  # Controle de conversas
‚îÇ   ‚îî‚îÄ‚îÄ device_detector.py   # Detec√ß√£o inteligente de dispositivos
‚îú‚îÄ‚îÄ context/                 # Gerenciamento de contexto e persist√™ncia
‚îÇ   ‚îú‚îÄ‚îÄ manager.py          # Context Manager principal
‚îÇ   ‚îú‚îÄ‚îÄ websocket_server.py # Servidor WebSocket para dashboard
‚îÇ   ‚îî‚îÄ‚îÄ rest_api.py         # API REST para consultas
‚îú‚îÄ‚îÄ conversation/            # Gerenciamento de sess√µes Realtime API
‚îÇ   ‚îú‚îÄ‚îÄ realtime_conversation.py  # Cliente WebSocket OpenAI
‚îÇ   ‚îî‚îÄ‚îÄ session.py          # Controle de sess√µes
‚îú‚îÄ‚îÄ core/                   # Componentes centrais do sistema
‚îÇ   ‚îú‚îÄ‚îÄ config_validator.py # Valida√ß√£o de configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py   # Sistema de logs
‚îÇ   ‚îî‚îÄ‚îÄ security.py         # Seguran√ßa e autentica√ß√£o
‚îú‚îÄ‚îÄ dashboard/              # Interface web React
‚îÇ   ‚îú‚îÄ‚îÄ src/components/     # Componentes React
‚îÇ   ‚îî‚îÄ‚îÄ package.json        # Depend√™ncias Node.js
‚îú‚îÄ‚îÄ realtime/               # Integra√ß√£o com OpenAI Realtime API
‚îÇ   ‚îú‚îÄ‚îÄ audio_handler.py    # Processamento de √°udio
‚îÇ   ‚îú‚îÄ‚îÄ session_manager.py  # Gerenciamento de sess√µes
‚îÇ   ‚îî‚îÄ‚îÄ tools/              # Ferramentas dispon√≠veis
‚îú‚îÄ‚îÄ transcription/          # Transcri√ß√£o de voz para texto
‚îÇ   ‚îî‚îÄ‚îÄ simple_transcriber.py  # Transcritor em tempo real
‚îú‚îÄ‚îÄ triggers/               # Sistema de gatilhos
‚îÇ   ‚îú‚îÄ‚îÄ manager.py          # Gerenciador de triggers
‚îÇ   ‚îú‚îÄ‚îÄ builtin/            # Triggers pr√©-constru√≠dos
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py         # Pipeline de execu√ß√£o
‚îú‚îÄ‚îÄ tts/                    # Text-to-Speech
‚îÇ   ‚îú‚îÄ‚îÄ openai_tts_simple.py  # Integra√ß√£o OpenAI TTS
‚îÇ   ‚îî‚îÄ‚îÄ audio_output.py     # Sa√≠da de √°udio
‚îú‚îÄ‚îÄ main.py                 # Ponto de entrada principal
‚îú‚îÄ‚îÄ config.py               # Configura√ß√µes globais
‚îî‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python
```

### Componentes Principais

- **Audio Pipeline**: Captura e processa √°udio em tempo real com detec√ß√£o de dispositivos
- **Context Manager**: Mant√©m contexto de conversas com persist√™ncia e acesso via API
- **Trigger System**: Sistema extens√≠vel de gatilhos com valida√ß√£o LLM
- **Realtime Integration**: Cliente WebSocket para OpenAI Realtime API
- **Dashboard**: Interface React para monitoramento e controle

---

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
# OpenAI API Key (obrigat√≥rio)
OPENAI_API_KEY=sk-...

# Integra√ß√µes opcionais
GOOGLE_API_KEY=...              # Para pesquisa Google
GOOGLE_SEARCH_ENGINE_ID=...     # ID do motor de busca
HUBSPOT_ANALYSIS_URL=...        # URL da API HubSpot
```

### Arquivo de Configura√ß√£o Principal

O arquivo `config.py` cont√©m todas as configura√ß√µes do sistema:

```python
# Configura√ß√µes de √°udio
AUDIO_CONFIG = {
    "sample_rate": 16000,
    "channels": 1,
    "chunk_duration_ms": 100
}

# Configura√ß√µes de triggers
TRIGGER_CONFIG = {
    "enabled": True,
    "validation_timeout": 5.0,
    "confidence_threshold": 0.7
}

# Configura√ß√µes do dashboard
DASHBOARD_CONFIG = {
    "host": "localhost",
    "port": 3000
}
```

### Configurando Novos Triggers

Para adicionar novos gatilhos proativos:

1. Crie um arquivo em `triggers/builtin/`
2. Herde da classe `BaseTrigger`
3. Configure palavras-chave e l√≥gica de execu√ß√£o
4. Registre no `TriggerManager`

Exemplo:
```python
class MeuTrigger(BaseTrigger):
    keywords = ["palavra-chave"]
    
    async def execute(self, context):
        # Sua l√≥gica aqui
        return "Resposta do trigger"
```

### Logs e Monitoramento

Os logs s√£o salvos em:
- `logs/voice_assistant.log` - Log principal
- `logs/errors.log` - Apenas erros

Configure o n√≠vel de log em `config.py`:
```python
LOGGING_CONFIG = {
    "level": "INFO",  # DEBUG, INFO, WARNING, ERROR
    "format": "detailed"
}
```

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## üìû Contato

Para d√∫vidas ou sugest√µes sobre o Always On AI, entre em contato atrav√©s dos canais oficiais da empresa.
